Filename,First Author,Year,Findings,Keywords
Binz_-_Using_cognitive_psychology_to_understand_GPT-3_(2022).pdf,Binz,2022,"GPT-3 demonstrates impressive decision-making and information search abilities, outperforming humans in certain tasks, but shows weaknesses in causal reasoning. Small perturbations in tasks can lead GPT-3 astray, highlighting the need for further investigation using cognitive psychology tools.","GPT-3, cognitive psychology, decision-making, causal reasoning, language models"
Blaser_-_How_to_Use_AI_for_Diplomacy_-_(2023).pdf,Blaser,2023,Notable quotes by Anthony Blinken regarding AI. Idea to use AI to predict potential conflicts. This is a similar to idea by colleague who developed the Guardian software. Also mentioned that there was considerable improvement in productivity using AI tools.,"Blinken, ChatGPT, productivity"
Brand_-_Using_GPT_for_Market_Reearch_(2023).pdf,Brand,2023,GPT-3.5 responds to survey questions in line with economic theory and consumer behavior patterns. Estimates of willingness-to-pay from GPT-3.5 align with human-generated estimates. GPT-3.5 shows potential as a low-cost and efficient tool for market research.,"Large Language Models, GPT-3.5, Market Research, Consumer Preferences, Willingness-to-Pay"
Danica_Dillion_-_Can_AI_language_models_replace_human_participants_(2023).pdf,Danica Dillion,2023,"AI language models like GPT can make human-like judgments in various domains, potentially replacing human participants in psychological science. Language models have shown alignment with human judgments in moral scenarios and other tasks, indicating their potential as synthetic AI participants.","AI language models, human-like judgments, psychological science, synthetic participants, moral scenarios"
Deuksin_Kwon_Are_LLMs_Effective_Negotiators_Systematic_Evaluation_of_the_Multifaceted_Capabilities_of_LLMs_in_Negotiation_Dialogues_(2024).pdf,Deuksin Kwon,2024,LLMs show remarkable performance in various text comprehension tasks but struggle with generating contextually appropriate and strategically advantageous responses in negotiation dialogues. GPT-4 outperforms other models but still correlates poorly with human judgments in subjective assessments.,"Large Language Models, Negotiation Dialogues, Automated Systems"
Emery_-_Moral_Choices_Without_Moral_Language_(2021).pdf,Emery,2021,"The early 1950s at the RAND Corporation saw a significant intellectual contestation between the Mathematics and Social Sciences Divisions regarding the impact of nuclear weapons on war and international politics. The creation of political-military simulations highlighted divergent outcomes, with mathematicians favoring quick nuclear weapon deployment and social scientists showing nuclear restraint, emphasizing the role of emotions in decision-making and ethics.","RAND Corporation, nuclear weapons, political-military simulations, Mathematics Division, Social Sciences Division, emotions in decision-making, ethics"
Federico_Bianchi_How_Well_Can_LLMs_Negotiate_NEGOTIATION_ARENA_Platform_and_Analysis_(2024).pdf,Federico Bianchi,2024,"LLMs can significantly improve negotiation outcomes by employing specific behavioral tactics, such as pretending to be desperate. The study reveals irrational negotiation behaviors exhibited by LLM agents and identifies GPT-4 as the best negotiator among state-of-the-art LLMs.","Negotiation abilities, large language models (LLMs), behavioral tactics"
Florian_E._Dorner_DO_PERSONALITY_TESTS_GENERALIZE_TO_LARGE_LANGUAGE_MODELS_(2023).pdf,Florian E. Dorner,2023,"Large language models' responses to personality tests deviate from typical human responses, indicating that test results cannot be interpreted the same way. LLMs fail to replicate the five-factor structure found in human responses, suggesting that measurement models valid for humans do not fit for LLMs.","Large Language Models, Personality Tests, Validity"
Gabriel_Mukobi_WELFARE_DIPLOMACY_BENCHMARKING_LANGUAGE_MODEL_COOPERATION_(2023).pdf,Gabriel Mukobi,2023,Welfare Diplomacy (WD) leads to clearer evaluations of and stronger selection pressures for cooperative capabilities in AI systems. State-of-the-art models attain high social welfare but are exploitable in WD.,"Welfare Diplomacy, cooperative AI, benchmarking, multi-agent systems, language models"
Grossman_-AI_and_the_transformation_of_social_science_research_(2023).pdf,Grossman,2023,"AI, particularly large language models, can transform social science research by simulating human responses and behaviors, potentially replacing human participants for data collection. These models can reduce bias, enhance policy analysis, simulate social interactions, and provide new insights into human behavior and social dynamics.","AI, large language models, social science research, data collection, bias management, policy analysis, social interactions, human behavior"
Horton_-_Large_Language_Models_as_Simulated_Economic_Agents-_What_Can_We_Learn_from_Homo_Silicus-_(2023).pdf,Horton,2023,Large language models (LLMs) can be used as simulated economic agents (homo silicus) to explore human behavior in economic scenarios via simulation. Experiments using LLMs show qualitatively similar results to traditional economic experiments and offer a cost-effective way to pilot studies for generating novel social science insights.,"Large language models, Simulated economic agents, Behavioral economics"
Hutson_-_newyorker.com-Can_Computers_Learn_Common_Sense_(2022).pdf,Hutson,2022,Common sense is a critical but challenging aspect for artificial intelligence systems. Lack of common sense leads to AI systems struggling with unforeseen circumstances and making mistakes. Researchers are exploring ways to imbue AI systems with common sense to enhance their functionality and address various real-world challenges.,"Common sense, artificial intelligence, machine learning"
Hutson_-_science.org_-Guinea_pigbots_(2024).pdf,Hutson,2024,"Language models like GPT can mimic human behavior effectively, potentially replacing human subjects in various fields of research. These models can be used to conduct experiments, simulate diverse participant samples, adopt different personalities, and study consumer behavior.","Language models, Human behavior mimicry, Research experiments"
Ian_Gemp_States_as_Strings_as_Strategies_Steering_Language_Models_with_Game-Theoretic_Solvers_(2024).pdf,Ian,2024,"Integration of large language models with game theory to model strategic interactions in dialogue, demonstrating the potential to compute stable conversational strategies and generate dialogue scenarios grounded in real-world applications.","Large Language Models, Game Theory, Strategic Interactions"
Jiang_-_PersonaLLM-_Investigating_the_Ability_of_Large_Language_Models_to_Express_Personality_Traits_(2024).pdf,Jiang,2024,"LLM personas accurately reflect their assigned personality traits based on self-reported BFI scores and writing tasks. Human evaluators can perceive some personality traits with up to 80% accuracy, but accuracy drops when informed of AI authorship.","Large Language Models, Personality Traits, Human Evaluation"
Johnathan_Mell_Human-Like_Agents_for_Repeated_Negotiation_(2017).pdf,Johnathan,2017,"Virtual agents in negotiation need to incorporate human-like strategies such as trust, emotions, and social factors to be effective partners and teachers. Developing agents that can reason about strategy, model opponent preferences, and use emotions effectively is crucial for teaching negotiation skills.","Virtual agents, negotiation skills, human-like strategies"
Joon_Sung_Park_Generative_Agents_Interactive_Simulacra_of_Human_Behavior_(2023).pdf,Joon Sung Park,2023,"Generative agents simulate believable human behavior by storing, synthesizing, and applying memories to generate behavior. The agents exhibit individual and emergent social behaviors, such as planning activities, forming relationships, and coordinating group events.","Generative agents, Believable human behavior, Memory synthesis"
Juan-Pablo_Rivera_Escalation_Risks_from_Language_Models_in_Military_and_Diplomatic_Decision-Making_(2024).pdf,Juan-Pablo Rivera,2024,"Off-the-shelf large language models (LLMs) exhibit escalation tendencies in simulated wargames, leading to arms-race dynamics and potential deployment of nuclear weapons. Models justify actions based on deterrence and first-strike tactics, highlighting the need for caution in deploying autonomous language model agents in military and diplomatic decision-making.","Language Models, Escalation Risks, Wargame Simulations"
Junkai_Li_Agent_Hospital_A_Simulacrum_of_Hospital_with_Evolvable_Medical_Agents_(2024).pdf,Junkai Li,2024,"Doctor agents in Agent Hospital can improve treatment performance over time without manually labeled data, achieving state-of-the-art accuracy on medical tasks. The simulation environment effectively assists the evolution of LLM agents in dealing with specific medical tasks.","Agent Hospital, LLM agents, MedAgent-Zero strategy, medical simulation, doctor agents"
J_nos_Kram_r_Negotiation_and_honesty_in_artificial_intelligence_methods_for_the_board_game_of_Diplomacy_(2022).pdf,Janos Kramer,2022,Artificial agents using negotiation algorithms outperform those lacking this ability in Diplomacy. Sanctioning deviators who break contracts fosters truthful communication among agents.,"Negotiation algorithms, Diplomacy, trustworthy communication"
Lamparth_-_Human_vs._Machine-_Behavioral_Differences_Between_Expert_Humans_and_Language_Models_in_Wargame_Simulations_(2024).pdf,Lamparth,2024,"Significant qualitative and quantitative differences exist between human and large language model (LLM) responses in wargame simulations, with LLMs showing biases in violence levels and strategic tendencies. LLMs lack the ability to simulate human player characteristics accurately, highlighting the need for caution in granting autonomy or following AI-based strategy recommendations.","Wargame simulations, large language models (LLMs), human vs. machine behavior"
Lamparth_-_Why_the_Military_Can_t_Trust_AI___Foreign_Affairs_(2024).pdf,Lamparth,2024,"highlights significant concerns about integrating artificial intelligence into military decision-making, especially in nuclear warfare contexts. It emphasizes the unreliability of large language models, their vulnerability to adversarial attacks, and their lack of contextual understanding in complex geopolitical situations. The piece warns of the potential for unintended escalation due to AI's rapid decision-making capabilities and stresses the continued importance of human judgment in military operations. Additionally, it points out challenges in AI governance and the potential destabilization of current nuclear deterrence strategies, advocating for a cautious approach to AI adoption in military contexts.","AI Unreliability, Military Decision-Making, Nuclear Risk"
Lewis_D._Griffin_Large_Language_Models_respond_to_Influence_like_Humans_(2023).pdf,Lewis D. Griffin,2023,"Large Language Models (LLMs) can model psychological change following exposure to influential input, showing similar effects to human populations but with greater variability. LLMs can replicate effects of populist framing of news on persuasion and political mobilization observed in human studies.","Large Language Models, psychological change, Illusory Truth Effect, populist framing, influence"
Meta_Fundamental_AI_Research_Diplomacy_Team_(FAIR)_Human-level_play_in_the_game_of_Diplomacy_by_combining_language_models_with_strategic_reasoning_(2022).pdf,Meta Fundamental AI Research Diplomacy Team (FAIR),2022,"An AI agent named Cicero achieved human-level performance in the game of Diplomacy by combining language models with strategic reasoning. Cicero ranked in the top 10% of participants in an online Diplomacy league, outperforming human players.","AI agent, Diplomacy game, language models, strategic reasoning, human-level performance"
Microsoft_Office_User_-_Unknown_Title_(2024).pdf,Microsoft,2024,"Large language models (LLMs) like ChatGPT are transforming psychological research by simulating human cognition and behavior, offering innovative tools for various aspects of research. While LLMs advance research methodologies in psychology, ethical considerations such as data privacy and limitations awareness are crucial.","Large language models, Psychological research, Artificial intelligence"
Minghao_Wu_(PERHAPS)_BEYOND_HUMAN_TRANSLATION_HARNESSING_MULTI-AGENT_COLLABORATION_FOR_TRANSLATING_ULTRA-LONG_LITERARY_TEXTS_(2024).pdf,Minghao Wu,2024,"Translations from TRANS AGENTS are preferred by both human evaluators and LLMs over human-written references, especially in genres requiring domain-specific knowledge. Despite lower d-BLEU scores, TRANS AGENTS excels in generating translations with diverse and vivid descriptions.","Literary translation, multi-agent collaboration, large language models, evaluation strategies"
Murray_Shanahan_Role_play_with_large_language_models_(2023).pdf,Murray,2023,"Role play is a key concept in understanding the behavior of large language models (LLMs) used as dialogue agents. LLMs can convincingly mimic human language use but lack the cognitive capacities acquired through embodied interaction. Applying folk psychological language to describe LLMs can lead to anthropomorphism, highlighting the need for alternative conceptual frameworks.","large language models, dialogue agents, role play, anthropomorphism, conceptual frameworks"
Nikita_Mehandru_Evaluating_large_language_models_as_agents_in_the_clinic_(2024).pdf,Nikita Mehandru,2024,"Large language models (LLMs) can act as intelligent agents in healthcare settings, influencing clinical decision-making and improving clinical workflows. The development and evaluation of LLM agents for clinical use, including simulations using agent-based modeling, are crucial for their successful deployment.","Large language models, Intelligent agents, Healthcare settings, Clinical decision-making, Agent-based modeling, Simulation, Clinical workflows"
Nunzio_Lor__Strategic_Behavior_of_Large_Language_Models_Game_Structure_vs._Contextual_Framing_(2023).pdf,Nunzio Lor,2023,GPT-3.5 is sensitive to contextual framing but lacks abstract strategic reasoning; GPT-4 prioritizes game structure over context with a binary threshold approach; LLaMa-2 shows nuanced understanding of game structures and incorporates contextual factors into decision-making.,"Large Language Models, strategic decision-making, game theory"
Park_-_Diminished_Diversity-of-Thought_in_a_Standard_Large_Language_Model_(2023).pdf,Park,2023,"The study found that Large Language Models (LLMs) like GPT3.5 exhibited a 'correct answer' effect, providing consistent responses to nuanced questions. This phenomenon raises concerns about the validity of using LLMs as substitutes for human participants in social science studies and highlights a potential lack of diversity of thought in AI-led futures.","Large Language Models, GPT3.5, diversity of thought, social science, psychology, replication"
Qingyun_Wu_AutoGen__Enabling_Next-Gen_LLM_Applications_via_Multi-Agent_Conversation_(2023).pdf,Qingyun Wu,2023,"AutoGen is a framework that enables developers to build LLM applications using multi-agent conversations, allowing for customizable agents that can converse with each other and operate in various modes. The framework supports flexible conversation patterns and can be used for diverse applications with different complexities and LLM capacities.","AutoGen framework, LLM applications, multi-agent conversations"
Reddie_-_Next-generation_wargames_(2018).pdf,Reddie,2018,"The paper discusses the evolution of wargames for evaluating strategic decisions, the challenges of incorporating human factors into simulations, and the shift towards experimental gaming approaches for policy-making and academic research.","Wargames, simulation, experimental gaming, policy-making, human factors"
Riley_Simmons-Edler_-__AI-Powered_Autonomous_Weapons_Risk_Geopolitical_Instability_and_Threaten_AI_Research_(2024).pdf,Riley Simmons-Edler,2024,"The development of AI-powered autonomous weapons systems poses serious risks to geopolitical stability and the free exchange of ideas in AI research. The substitution of autonomous weapons for human soldiers increases the likelihood of conflicts and arms races, threatening global stability and AI research.","AI-powered autonomous weapons, geopolitical instability, AI research"
"Sahar_Abdelnabi_Cooperation,_Competition,_and_Maliciousness_LLM-Stakeholders_Interactive_Negotiation_(2024).pdf",Sahar,2024,"LLMs struggle in complex negotiation scenarios involving cooperation, competition, and manipulation. GPT-4 and other large models underperform in dynamic multi-agent negotiation games. Adversarial setups can lead to manipulation and deception among AI agents.","Large Language Models, Multi-agent Systems, Negotiation, Cooperation, Competition, Manipulation"
Shannon_Monahan_Autonomous_Agent_that_Provides_Automated_Feedback_Improves_Negotiation_Skills_(2018).pdf,Shannon Monahan,2018,"Participants who received automated individualized feedback after the first negotiation showed significantly greater improvement in the strength of their first offer, concession curve, and final outcome in the negotiation.","Negotiation, Individualized feedback, Automated metrics"
Shibani_Santurkar_Whose_Opinions_Do_Language_Models_Reflect_(2023).pdf,Shibani,2023,"Current language models exhibit substantial misalignment with the opinions of various US demographic groups, even after fine-tuning. Certain demographic groups like 65+ and widowed individuals are poorly represented by these models.","Language models, Opinions, Alignment, Demographic groups"
Tian_Liang_Encouraging_Divergent_Thinking_in_Large_Language_Models_through_Multi-Agent_Debate_(2024).pdf,Tian Liang,2024,"Self-reflection methods in large language models suffer from the Degeneration-of-Thought problem, hindering the generation of novel ideas. The Multi-Agent Debate framework encourages divergent thinking in models, addressing the limitations of self-reflection and improving performance on complex reasoning tasks.","Large Language Models, Self-reflection, Degeneration-of-Thought problem, Multi-Agent Debate, Divergent Thinking"
Tim_R._Davidson_EVALUATING_LANGUAGE_MODEL_AGENCY_THROUGH_NEGOTIATIONS_(2024).pdf,Tim R. Davidson,2024,1. Closed-source models outperformed open-source models in negotiation games. 2. Cooperative bargaining games were the most challenging for the models. 3. Even powerful models sometimes lost to weaker opponents.,"Language Model Agency, Negotiation Games, LM Performance Evaluation"
Tom_S_hr_Challenging_the_Validity_of_Personality_Tests_for_Large_Language_Models_(2024).pdf,Tom Sohr,2024,"Personality tests for large language models (LLMs) do not yield results comparable to human responses, indicating a need for validation specific to LLMs. LLMs' responses to personality questionnaires deviate from expected human patterns and fail to replicate the five-factor structure found in human samples.","Large Language Models, Personality Tests, Measurement Invariance"
Tom_Young_From_Knowledge_Augmentation_to_Multi-tasking_Towards_Human-like_Dialogue_Systems_(2022).pdf,Tom Young,2022,"The paper focuses on bridging the gap between task-oriented and open-domain dialogues, grounding dialogues on the audio modality and commonsense knowledge, and improving the computational efficiency of large-scale response retrieval in dialogue systems.","Dialogue systems, task-oriented dialogues, audio modality, commonsense knowledge, response retrieval, computational efficiency"
Trieu_H._Trinh_-_Solving_olympiad_geometry_without_human_demonstrations_(2024).pdf,Trieu H. Trinh,2024,"AlphaGeometry, a neuro-symbolic system, solves olympiad-level geometry problems without human demonstrations, outperforming previous methods and approaching the performance of top human solvers. The method generates synthetic data, produces human-readable proofs, and addresses the scarcity of training data in geometry theorem proving.","Theorem proving, geometry, synthetic data generation, neuro-symbolic system, olympiad-level problems"
Volodymyr_Mnih_-_Human-level_control_through_deep_reinforcement_learning_(2015).pdf,Volodymyr Mnih,2015,"The paper introduces a deep Q-network (DQN) that combines reinforcement learning with deep neural networks to learn successful policies directly from high-dimensional sensory inputs. The DQN agent outperformed previous algorithms and achieved human-level performance on a variety of challenging tasks, demonstrating the capability to excel at diverse tasks using only pixels and game scores as inputs.","Deep reinforcement learning, deep Q-network, high-dimensional sensory inputs"
Yadong_Zhang_A_Survey_of_Strategic_Reasoning_with_Large_Language_Models_(2024).pdf,Yadong Zhang,2024,"Large Language Models (LLMs) are being utilized for strategic reasoning in multi-agent settings, enabling the understanding and prediction of adversary actions. Strategic reasoning with LLMs involves adjusting strategies based on dynamic and uncertain interactions among agents, showcasing potential in decision-making performance enhancements.","Large Language Models, Strategic Reasoning, Multi-agent Settings"
Yao_Fu_Improving_Language_Model_Negotiation_with_Self-Play_and_In-Context_Learning_from_AI_Feedback_(2023).pdf,Yao,2023,1. Strong language models can self-play and improve negotiation outcomes with AI feedback. 2. Models' abilities to learn from feedback vary based on the role they play in the negotiation. 3. Strong agents can improve performance over multiple rounds but face a higher risk of deal breakdown.,"Language models, Self-play, AI feedback, Negotiation, Improvement"
Yilun_Du_Improving_Factuality_and_Reasoning_in_Language_Models_through_Multiagent_Debate_(2023).pdf,Yilun Du,2023,"Multiagent debate approach significantly enhances mathematical and strategic reasoning in language models, improves factual validity of generated content, reduces fallacious answers and hallucinations, and leads to convergence on more accurate common answers.","Language models, multiagent debate, reasoning improvement, factual accuracy"
Yiran_Wu_MATHCHAT_CONVERSE_TO_TACKLE_CHALLENGING_MATH_PROBLEMS_WITH_LLM_AGENTS_(2024).pdf,Yiran Wu,2024,"MathChat, a conversational problem-solving framework using LLM agents, improves math problem-solving by 6% compared to previous methods. It achieves 60% accuracy on half of the categories in high school competition problems.","LLM agents, math problem-solving, conversational framework"
Yuncheng_Hua_Assistive_Large_Language_Model_Agents_for_Socially-Aware_Negotiation_Dialogues_(2024).pdf,Yuncheng Hua,2024,"The paper introduces assistive agents based on Large Language Models (LLMs) to aid in business negotiations by simulating negotiations and using a remediator agent to correct norm violations, resulting in improved negotiation outcomes.","Large Language Models, business negotiations, social intelligence, remediator agent, In-Context Learning"
"Zekun_Moore_Wang_RoleLLM_Benchmarking,_Eliciting,_and_Enhancing_Role-Playing_Abilities_of_Large_Language_Models_(2024).pdf",Zekun,2024,"RoleLLM framework enhances role-playing abilities in Large Language Models by introducing RoleBench dataset and RoleLLaMA/RoleGLM models, achieving competitive results with RoleGPT. Dialogue engineering is favored over prompt engineering for RoleGPT, and Context-Instruct significantly improves models' knowledge about roles.","Large Language Models, role-playing abilities, RoleLLM framework"
Zhe_Hu_Unlocking_Varied_Perspectives_A_Persona-Based_Multi-Agent_Framework_with_Debate-Driven_Text_Planning_for_Argument_Generation_(2024).pdf,Zhe Hu,2024,"The paper proposes a persona-based multi-agent framework for argument writing, where agents with distinct personas collaborate through debate-driven text planning to generate diverse and persuasive arguments. The framework enhances perspective diversity and logical coherence in argumentative essay writing.","Argument generation, persona-based framework, multi-agent collaboration, debate-driven planning, perspective diversity"
